<!doctype html><html lang="ja"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="description" content="MATLAB/Simulink に関するブログの更新をまとめたRSSフィードを配信しています。MATLAB の使い方・MATLAB を使った新しいアイデアのヒントが得られますように。"><meta name="author" content="minoue"><meta name="robots" content="index, follow"><meta property="og:url" content="https://minoue-xx.github.io/MATLAB-blog-rss-feed/"><meta property="og:title" content="matlab - kentaPtの日記のフィード｜MATLAB 関連ブログ RSS"><meta property="og:image" content="https://minoue-xx.github.io/MATLAB-blog-rss-feed/images/og-image.png"><meta property="og:description" content="MATLAB/Simulink に関するブログの更新をまとめたRSSフィードを配信しています。MATLAB の使い方・MATLAB を使った新しいアイデアのヒントが得られますように。"><meta property="og:type" content="website"><meta property="og:site_name" content="MATLAB 関連ブログ RSS"><meta name="twitter:card" content="summary"><meta property="twitter:domain" content="https://minoue-xx.github.io/MATLAB-blog-rss-feed/"><meta property="twitter:url" 
content="https://minoue-xx.github.io/MATLAB-blog-rss-feed/"><meta name="twitter:title" content="matlab - kentaPtの日記のフィード｜MATLAB 関連ブログ RSS"><meta name="twitter:description" content="MATLAB/Simulink に関するブログの更新をまとめたRSSフィードを配信しています。MATLAB の使い方・MATLAB を使った新しいアイデアのヒントが得られますように。"><meta name="twitter:image" content="https://minoue-xx.github.io/MATLAB-blog-rss-feed/images/og-image.png"><link rel="shortcut icon" href="../../images/favicon.ico"><link rel="apple-touch-icon" href="../../images/apple-icon.png"><link rel="alternate" type="application/atom+xml" title="Atom Feed" href="../../feeds/atom.xml"><link rel="alternate" type="application/rss+xml" title="RSS2.0" href="../../feeds/rss.xml"><link rel="alternate" type="application/json" href="../../feeds/feed.json"><style>
*,::after,::before{box-sizing:border-box}*{margin:0}body,html{height:100%}body{line-height:1.5;-webkit-font-smoothing:antialiased}canvas,img,picture,svg,video{display:block;max-width:100%}button,input,select,textarea{font:inherit}h1,h2,h3,h4,h5,h6,p{overflow-wrap:break-word}#__next,#root{isolation:isolate}:root{--ui-color-brand:#353535;--ui-color-n-000:#fff;--ui-color-n-100:#ebebeb;--ui-color-n-300:#aeaeae;--ui-color-n-500:#353535;--ui-color-n-700:#282828;--ui-color-n-900:#1a1a1a;--ui-color-background-primary:var(--ui-color-n-000);--ui-color-form-input:var(--ui-color-n-100);--ui-color-typography-heading:var(--ui-color-n-500);--ui-color-typography-body:var(--ui-color-n-900);--ui-color-typography-note:var(--ui-color-n-300);--ui-color-typography-button:var(--ui-color-n-000);--ui-typography-typeface:"Inter",sans-serif;--ui-typography-h1:1.9375rem;--ui-typography-h2:1.5625rem;--ui-typography-h3:1.25rem;--ui-typography-p:1rem;--ui-typography-s:.8125rem;--ui-typography-h1-leading:1.2;--ui-typography-h2-leading:1.2;--ui-typography-h3-leading:1.25;--ui-typography-p-leading:1.5;--ui-typography-margin-heading:.75rem;--ui-typography-margin-body:1.125rem;--ui-layout-container:1.25rem;--ui-layout-grid:3.625rem;--ui-layout-gutter:1rem;--ui-gap-cta:.75rem;--ui-gap-content:2rem;--ui-radius-button:5rem;--ui-radius-input:5rem}html{box-sizing:border-box}*,:after,:before{box-sizing:inherit}body{background-color:var(--ui-color-background-primary);color:var(--ui-color-typography-body);font-family:var(--ui-typography-typeface);font-feature-settings:"liga","kern";font-size:var(--ui-typography-p);font-weight:400;line-height:var(--ui-typography-p-leading);margin:0 auto;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased}a{color:var(--ui-color-brand);text-decoration:none}h1,h2,h3,p{margin-top:0}h1,h2,h3{color:var(--ui-color-typography-heading);margin-bottom:var(--ui-typography-margin-heading)}h1{font-size:var(--ui-typography-h1);line-height:var(--ui-typography-h1-leading)}h2{font-size:var(--ui-typography-h2);line-height:var(--ui-typography-h2-leading)}h3{font-size:var(--ui-typography-h3);line-height:var(--ui-typography-h3-leading)}p{margin-bottom:var(--ui-typography-margin-body)}p:last-child{margin-bottom:0}strong{font-weight:700}small{font-size:var(--ui-typography-s)}.ui-text-note{color:var(--ui-color-typography-note);line-height:1}img,svg{display:block;height:auto;margin:0 auto;max-width:100%}.ui-layout-container{padding-left:var(--ui-layout-container);padding-right:var(--ui-layout-container)}.ui-layout-flex,.ui-layout-grid{align-items:center;justify-content:center}.ui-layout-flex{display:flex}.ui-layout-grid{display:grid}.ui-component-cta{flex-direction:column;row-gap:var(--ui-gap-cta)}button,input{color:inherit;font-family:inherit;font-size:var(--ui-typography-p);line-height:1;margin:0;outline:0;text-rendering:inherit;text-transform:none}form{width:100%}.ui-component-form{background-color:var(--ui-color-form-input);border-radius:var(--ui-radius-input);grid-template-columns:minmax(0,1fr) auto;padding:.25rem}::placeholder{color:var(--ui-color-typography-note)}.ui-component-input{background-color:var(--ui-color-form-input);border:.0625rem solid var(--ui-color-form-input);border-radius:var(--ui-radius-input)}.ui-component-input-medium{height:2.5rem;padding:.625rem 1rem .75rem}button{background:0 0;border:0;cursor:pointer;display:block;padding:0}.ui-component-button{border:.0625rem solid var(--ui-color-brand);border-radius:var(--ui-radius-button);display:block;font-weight:700;line-height:1;text-align:center}.ui-component-button-primary{background-color:var(--ui-color-brand);color:var(--ui-color-typography-button)}.ui-component-button-medium{padding:.625rem .875rem .75rem;width:fit-content}.ui-section-header{padding-bottom:1.25rem;padding-top:1.25rem}.ui-section-header__layout{justify-content:space-between}.ui-section-content{padding-bottom:2em;padding-top:5rem;text-align:center}.ui-section-content--image{margin-bottom:var(--ui-gap-content);margin-top:var(--ui-gap-content)}.ui-section-content--feature{row-gap:var(--ui-gap-content)}.ui-section-content--icon{margin-bottom:1rem}.ui-section-close{padding-bottom:5rem;padding-top:5rem;text-align:center}.ui-section-footer{padding-bottom:1.25rem;padding-top:1.25rem}.ui-section-footer__layout{column-gap:var(--ui-layout-gutter)}.ui-section-footer--copyright{margin-bottom:0;margin-right:auto}@media screen and (min-width:48rem){:root{--ui-typography-h1:2.1875rem;--ui-typography-h2:1.75rem;--ui-typography-h3:1.4375rem;--ui-typography-p:1.125rem;--ui-typography-s:.875rem;--ui-typography-margin-body:1.25rem;--ui-layout-container:4.25rem;--ui-layout-gutter:1.5rem;--ui-gap-content:3rem}.ui-layout-column-center,.ui-layout-container{margin-left:auto;margin-right:auto}.ui-layout-grid-3{column-gap:var(--ui-layout-gutter);grid-template-columns:repeat(2,1fr);justify-items:center}.ui-layout-grid-3 div:last-of-type{left:calc(50% + (var(--ui-layout-gutter)/ 2));position:relative}.ui-layout-column-4{width:calc((var(--ui-layout-grid) * 4) + (var(--ui-layout-gutter) * 3))}.ui-layout-column-6{width:calc((var(--ui-layout-grid) * 6) + (var(--ui-layout-gutter) * 5))}.ui-section-header{padding-bottom:2rem;padding-top:2rem}.ui-section-content{padding-bottom:3rem}.ui-section-content--icon{height:4rem;width:4rem}.ui-section-footer{padding-bottom:2rem;padding-top:2rem}}@media screen and (min-width:64rem){:root{--ui-layout-container:0}a{transition:all 250ms ease}a:not(.ui-component-button):hover{color:var(--ui-color-typography-body)}.ui-layout-container{width:60rem}.ui-layout-grid-3{grid-template-columns:repeat(3,1fr)}.ui-layout-grid-3 div:last-of-type{position:static}}@media screen and (min-width:75rem){:root{--ui-typography-h1:2.75rem;--ui-typography-h2:2.1875rem;--ui-typography-h3:1.75rem;--ui-typography-h4:1.4375rem;--ui-typography-margin-heading:1rem;--ui-typography-margin-body:1.75rem;--ui-layout-grid:4rem;--ui-layout-gutter:2rem;--ui-gap-content:4rem}.ui-text-intro{font-size:var(--ui-typography-h4)}.ui-layout-container{width:70rem}.ui-section-header{padding-bottom:3rem;padding-top:3rem}.ui-section-content{padding-bottom:5rem;padding-top:7.5rem}.ui-section-content--icon{height:5rem;margin-bottom:1.125rem;width:5rem}.ui-section-close{padding-bottom:7.5rem;padding-top:7.5rem}.ui-section-footer{padding-bottom:3rem;padding-top:3rem}}:root{--material-color-yellow-50:#fffde7;--material-color-yellow-100:#fff9c4;--material-color-orange-500:#ff9800;--material-color-orange-600:#fb8c00;--base-background:#fff;--base-color:#333;--base-color-lighter:#777;--base-color-muted:#999;--yellow-background:var(--material-color-yellow-100);--yellow-background-lighter:var(--material-color-yellow-50);--orange-background-dark:var(--material-color-orange-500);--orange-background-dark-active:var(--material-color-orange-600);--hatena-color:#01a5df;--base-font:-apple-system,BlinkMacSystemFont,Helvetica Neue,Yu Gothic,YuGothic,Verdana,Meiryo,M+ 1p,sans-serif;--ui-gap-content:2em}.ui-text-note{color:var(--base-color-muted)}.ui-section-header__layout img{display:inline-block;width:24px;height:24px;vertical-align:middle}.ui-section-content{padding-top:2.5em;padding-bottom:3.5rem}.ui-section-header{padding-top:2rem;padding-bottom:1rem}.ui-component-form{border-radius:0;grid-template-columns:auto minmax(0,1fr) auto}.ui-component-form .ui-component-button{border-radius:0;background:var(--orange-background-dark);border-color:var(--orange-background-dark)}.ui-component-form .ui-component-button.active{background:var(--orange-background-dark-active);border-color:var(--orange-background-dark-active)}@media screen and (min-width:48rem){.ui-layout-grid-3 div:last-of-type{left:0}}@media screen and (min-width:75rem){.ui-layout-grid-3{grid-template-columns:repeat(4,1fr)}}.ui-typography-heading{text-align:left}.ui-typography-heading small{color:var(--base-color-muted)}img{color:var(--base-color-muted)}.ui-section-header__layout .ui-section-header__title{display:inline-block;line-height:22px;vertical-align:middle;font-weight:700;font-size:1.3em;color:var(--base-color)}.ui-top-section{padding-bottom:2em}.ui-component-form__label{margin-left:.2em}.ui-component-form__label img{width:32px;height:32px}.ui-component-form__label span{font-weight:700}.ui-top-section .ui-text-note{margin-bottom:.6em}.ui-top-section .ui-top-section__subscribe{margin-top:.3em;display:flex;gap:.5em}.ui-top-section .ui-top-section__subscribe img{height:37px;width:auto}.ui-section-nav__layout{justify-content:start}.ui-section-nav__link{font-weight:700;margin-right:1.5em;padding:.5em 0;border-bottom:2px solid transparent;color:var(--base-color-muted)}.ui-section-nav__link--active{color:var(--base-color);border-bottom-color:var(--base-color)}.ui-section-content__feed-date-heading{text-align:left;font-size:1.2em;color:var(--base-color-lighter);margin-top:1em;margin-bottom:1em;padding:.4em .3em;border-bottom:1px solid var(--base-color-lighter);position:sticky;top:0;z-index:1;background-color:var(--yellow-background-lighter)}.ui-section-feed{background:var(--yellow-background-lighter)}.ui-section-feed .ui-layout-grid{align-items:flex-start}.ui-section-feed .ui-text-note{text-align:left;font-size:.9em}.ui-container-feed{text-align:left;margin-top:1em;margin-bottom:2em;justify-items:left}.ui-container-feed.ui-container-feed--hot{margin-top:2em}.ui-feed-item{display:grid;color:var(--base-color);grid-template-columns:130px 1fr;align-content:start;grid-gap:0 0.5em}.ui-feed-item .ui-feed-item__og-image img{width:100%;height:auto;max-height:7em;object-fit:contain;object-position:center top}.ui-feed-item .ui-feed-item__title{font-weight:700;font-size:.9em;-webkit-line-clamp:3;-webkit-box-orient:vertical;display:-webkit-box;overflow:hidden;word-break:break-all}.ui-feed-item .ui-feed-item__title:hover{text-decoration:underline}.ui-feed-item .ui-feed-item__title:visited{color:var(--base-color-lighter)}.ui-feed-item .ui-feed-item__hatena-count{margin:.1em 0;font-size:.7em}.ui-feed-item .ui-feed-item__hatena-count img{display:inline;width:1.25em;height:1.25em;vertical-align:middle}.ui-feed-item .ui-feed-item__hatena-count span{color:var(--hatena-color);font-weight:700;vertical-align:middle}.ui-feed-item .ui-feed-item__blog-title{margin:.3em 0;font-size:.75em}.ui-feed-item .ui-feed-item__blog-title--link:hover{text-decoration:underline}.ui-feed-item .ui-feed-item__summary{font-size:.75em;margin:.3em 0;word-break:break-all;overflow:hidden;-webkit-line-clamp:2;-webkit-box-orient:vertical;display:-webkit-box;color:var(--base-color-muted)}.ui-feed-item .ui-feed-item__date{color:var(--base-color-muted);font-size:.7em}@media screen and (min-width:48rem){.ui-feed-item{display:block}.ui-feed-item .ui-feed-item__og-image{display:block}.ui-feed-item .ui-feed-item__og-image img{height:9em;max-height:9em}.ui-feed-item .ui-feed-item__title{margin-top:.5em}}@media screen and (min-width:75rem){.ui-feed-item .ui-feed-item__og-image img{height:8em;max-height:8em}}.ui-section-blog{background:var(--yellow-background-lighter)}.ui-container-blog{text-align:left;margin-top:2em}.ui-blog{display:grid;color:var(--base-color);grid-template-columns:130px 1fr;align-content:start;grid-gap:0 0.5em}.ui-blog .ui-blog__og-image img{width:100%;height:auto;max-height:7em;object-fit:contain;object-position:center top}.ui-blog .ui-blog__title{display:block;font-weight:700;word-break:break-all}.ui-blog .ui-blog__title:hover{text-decoration:underline}.ui-blog .ui-blog__link{display:block;font-size:.7em;word-break:break-all;overflow:hidden;margin:.2em 0}.ui-blog .ui-blog__link:hover{text-decoration:underline}.ui-blog .ui-blog__description{font-size:.75em;margin:.3em 0;word-break:break-all;overflow:hidden;-webkit-line-clamp:2;-webkit-box-orient:vertical;display:-webkit-box;color:var(--base-color-muted)}.ui-blog .ui-blog__date{color:var(--base-color-muted);font-size:.7em}@media screen and (min-width:48rem){.ui-blog{display:block}.ui-blog .ui-blog__og-image{display:block}.ui-blog .ui-blog__og-image img{width:auto;height:9em;max-height:9em}.ui-blog .ui-blog__title{margin-top:.5em}}@media screen and (min-width:75rem){.ui-blog .ui-blog__og-image img{width:auto;height:8em;max-height:8em}}.ui-container-blog-summary{text-align:left;margin-bottom:2em}.ui-blog-summary .ui-blog-summary__link{display:block;word-break:break-all;overflow:hidden;margin:.2em 0}.ui-blog-summary .ui-blog-summary__link:hover{text-decoration:underline}.ui-blog-summary .ui-blog-summary__description{margin:.3em 0;word-break:break-all;color:var(--base-color-muted)}.ui-section-footer .ui-section-footer__site-info{margin-bottom:1.5em;display:block;font-size:.9em}.ui-section-footer .ui-section-footer__site-info .ui-text-note{margin-bottom:.7em;line-height:1.4em}
</style><title>matlab - kentaPtの日記のフィード｜MATLAB 関連ブログ RSS</title></head><body><header role="banner" class="ui-section-header"><div class="ui-layout-container"><div class="ui-section-header__layout ui-layout-flex"><a href="https://minoue-xx.github.io/MATLAB-blog-rss-feed/" role="link" aria-label="#"><img src="../../images/icon.png" alt="サイトロゴ" loading="lazy" decoding="async" width="96" height="96"> <span class="ui-section-header__title">MATLAB 関連ブログ RSS</span> </a><a href="https://github.com/minoue-xx/MATLAB-blog-rss-feed/" role="link" aria-label="#"><img src="../../images/github-mark.png" alt="GitHubロゴ" loading="lazy" decoding="async" width="96" height="96"></a></div></div></header><main role="main"><nav class="ui-nav"><div class="ui-layout-container"><div class="ui-section-nav__layout ui-layout-flex"><a class="ui-section-nav__link" href="../../">フィード</a> <a class="ui-section-nav__link" href="../../hot/">人気フィード</a> <a class="ui-section-nav__link" href="../../blogs/">ブログ一覧</a></div>
</div></nav><section class="ui-section-content ui-section-feed"><div class="ui-layout-container"><h2 class="ui-typography-heading">matlab - kentaPtの日記</h2><div class="ui-container-blog-summary"><div class="ui-blog-summary"><a class="ui-blog-summary__link" href="https://kentapt.hatenablog.com/archive/category/matlab">https://kentapt.hatenablog.com/archive/category/matlab</a><p class="ui-blog-summary__description">主に画像解析のことなどの勉強記録として投稿します。もし何かございましたら、github (https://github.com/KentaItakura)などからご連絡いただけると幸いです。</p></div></div><h3 class="ui-typography-heading">フィード</h3><div class="ui-section-content--feature ui-layout-grid ui-layout-grid-3 ui-container-feed ui-container-feed--no-image"><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/matlabAdventDay12"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a 
class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/matlabAdventDay12">サポートベクトルマシン（SVM）を簡単に、わかりやすく説明したい</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
この記事は、MATLABアドベントカレンダー（その2）の12日目の記事として書かれています。 qiita.com 1 はじめに 本記事では、サポートベクトルマシン（Support Vector Machine: SVM）の仕組みについてまとめます。 サポートベクトルマシンは複数の次元を有するデータを超平面で分離する手法として有名です。色々な場面で利用でき、機械学習の代表的な手法の1つ言えます。以下の図は、3つの変数をもつデータを2つのクラスに分類しているときの図です。各軸が、それぞれの変数に対応しています。また、赤色の局面（超平面）によって、2つのクラスに分類されます。この図は3変数の場合を示していますが、これがより多くの変数の数（次元）になっても問題ありません。このように2つのクラスを超平面（曲面）でうまく分類できると非常に便利そうで、かつおもしろいです。本記事では、このサポートベクトルマシンがどのように計算されるのかを紹介したいと思います。 このサポートベクトルマシンの分離平面を可視化するためのコード (Python、MATLAB）は以下のブログやfile exchangeにて公開しています。もしよろしければ、こちらもご覧ください。 過去の記事：サポートベクターマシン（SVM）の分離平面の可視化 (Python, MATLAB) kentapt.hatenablog.com File Exchange: Visualizing a hyper-plane in SVM classifier（SVMの分離境界面の可視化） jp.mathworks.com また、本記事を執筆するにあたり、私の理解に基づき、2クラス分類のサポートベクトルマシンを1から実装し（ただしかなりおおばっぱな実装です）、以下のようなそれらしい結果を得ることができました。赤丸と青丸がそれぞれ異なるクラスに属するサンプルで、赤線と青線がそれぞれを分類（分離）する境界です。赤色および青色のサンプルはそれぞれ、同じ色の境界で囲まれていて、うまく分類ができていそうです。 下の図は、本記事で説明する、正則化項の値を値を変えながら学習した時の、境界です。 また、下の図は、ガウシアンカーネルのパラメータを変化させながら学習させたときの境界になります。 本記事の執筆にあたっては、 赤穂先生の「カーネル多変...
</div><div class="ui-feed-item__date" title="2023-01-01 11:00:00">7ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/matlabAdventDay6"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/matlabAdventDay6">重回帰分析の勉強＆実装による検算をしてみよう</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
この記事は、MATLABアドベントカレンダー（その2）の6日目の記事として書かれています。 qiita.com 1 はじめに 前回の記事では、1つの変数のみで、線形回帰（単回帰）を行うときの、数式の導出や自身の実装による検算を行いました。 線形回帰（単回帰分析）を1から実装して理解を深めてみよう kentapt.hatenablog.com 線形回帰（単回帰分析）を1から実装して理解を深めてみよう: つづき kentapt.hatenablog.com そこでは、y = ax + bという非常にシンプルな場合を扱いました。 今回は、 といったような、変数の数を増やした場合について考えたいと思います。 そこで、本記事では、変数の数を増やして線形回帰（重回帰分析）をしたときの、計算方法について簡単にまとめます。さらに、MATLABを用いてコーディングをし、ここでの理解による実装の結果と、MATLABのregress関数の結果が一致することを確かめます。本記事は、タイプミスや間違いなどがあるかもしれません。その場合教えていただけますと幸いです。また、本記事は、前回の記事をもとに、執筆をしており、説明が比較的少なくなっています。もしよろしければ、先述した前回の記事も見ていただけますと幸いです。 また、本記事の原稿や用いたコードは以下のページにアップロードされています。 github.com 本記事の執筆においては、以下の資料が非常に参考になりました。 回帰分析（重回帰） http://fs1.law.keio.ac.jp/~aso/ecnm/pp/reg2.pdf 2 重回帰分析について 重回帰モデル (multiple regression model) とは、単回帰とは異なり、説明変数が複数ある回帰モデルのことです。 モデル式は、線形回帰に変数をさらに加えて以下のようになります。 ...(1) 単回帰のときと同様に、誤差を2乗して、足したもの（残差平方和）を求めます。 ...(2) 前回の記事と同様に、各変数で偏微分を行います。 のようにおいて、合成関数の微分を行っています。 aおよびに対して、偏微分を行った時の式を以下に記述します。 ...(3) yを左辺に移動させて、両辺を-2で割り、整理すると以下のようになります。 この式を正規方程式（no...</div>
<div class="ui-feed-item__date" title="2022-12-30 12:55:54">7ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/2022/12/22/matlabAdventDay22"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/2022/12/22/matlabAdventDay22">iPhone LiDARで取得した3次元点群の境界を書き出してみよう</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
この記事は、MATLABアドベントカレンダー22日目の記事として書かれています。 qiita.com この記事の前編として以下の記事も投稿しています。ぜひご覧ください。 kentapt.hatenablog.com この記事では、iPhone LiDARで取得した3次元点群をMATLABにて読み込み、さらに、その領域の境界のデータをKMLファイルとして出力する方法を紹介します。言語はMATLABを使用します。 3次元点群を取得するためのアプリは3D Scanner Appを用いました。 詳しい使い方は、以下の記事がわかりやすかったです。 note.com また、以下の記事でもこちらのアプリの使い方を紹介しています。 note.locusblue.com ここでは、すでにiPad LiDARにて計測し、PCに転送した状態から始めます。 なお、ここで用いたコードや、点群ファイルは以下のページにアップロードされています。 github.com 点群ファイルの読み込み LiDAR toolboxの機能を用いて、点群データの読み込みを行います。以下のように、lasFileReaderやreadPointCloud関数を用いて、簡単に点群ファイルを読み込むことができます。まずは、GPS情報を有した点群（LAS）ファイルをそのまま読み込み、表示してみます。なお、上のgithubのページでは、ファイルサイズを小さくするため、サンプルファイルのファイル形式をLAZ形式に圧縮してアップロードしています。（3D Scanner Appでは、LAS形式で点群がエキスポートされます。）MATLABに読み込む方法などは変わりません。 clear;clc;close all % las/lazファイルを読み込むためのlasFileReader objectを作成する lasReader = lasFileReader(&#39;sample.laz&#39;); % las/lazファイルの、xyzおよび色情報を読み込み ptCloud = readPointCloud(lasReader); % 可視化 figure;pcshow(ptCloud) しかし、単に読み込むだけでは、このように、うまく表示できません。2022年12月現在、3D Scanner Appから、Geo-referenceされた（...
</div><div class="ui-feed-item__date" title="2022-12-22 12:40:08">8ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/matlabAdventDay21"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/matlabAdventDay21">深層学習を用いた物体検出の手法（YOLOv2）についてのまとめ</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
この記事は、MATLABアドベントカレンダー（その2）の21日目の記事として書かれています。 qiita.com はじめに この記事では、物体検出の有名な手法である、YOLOv2について説明を行います。物体検出の手法を用いて、以下のように画像中から対象を自動的に検出することができます。 YOLOにより物体を検出しているときの動画の例も挙げます。以下の動画をご覧ください。 YOLOモデルは物体検出において非常に有名で、様々なバージョンが公開されています。この中でも、ネットワークがシンプルで、比較的高速かつ高精度に物体検出ができる、YOLOv2についてまとめたいと思います。YOLOなどの物体検出ネットワークの仕組みを説明した記事は多く存在します。本記事では、もとの論文の和訳をして、作者による説明を把握しつつ、適宜、補足説明を行います。これにより、論文をベースにした情報に触れながらも、（まずはぼんやりと）内容の理解の進む記事になればよいなと思いました。 そこで、本記事では、以下のリンクにある Redmon and Farhadi (2017) の論文の、Introductionと、Betterのセクションの和訳を行い、さらに、適宜、筆者の理解による補足を行います。特にBetterセクションでは、図を追加して、YOLOv2の原理について説明を行います。これにより、元の論文の流れをベースとして、YOLOv2の概要をつかみやすくすることを目指します。本記事を通して、物体検出の方法の理解度が上がれば嬉しく思います。なお、本論文では、以下の論文から図を引用しております。 [論文情報] Redmon, J., &amp; Farhadi, A. (2017). YOLO9000: better, faster, stronger. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 7263-7271). [論文のリンク] arxiv.org なお、本記事で用いたコードや本文の原稿は以下のページにアップロードされています。 github.com 論文の和訳 それでは、さっそく論文のIntroductionから和訳を行っていきます。また、和訳に関しては、筆者の勝手な理解...
</div><div class="ui-feed-item__date" title="2022-12-18 10:00:30">8ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/matlabAdventDay19"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/matlabAdventDay19">iPadで数式を書いて、MATLAB livescriptでブログ記事を書いてみよう</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
この記事は、MATLABアドベントカレンダー（その2）の19日目の記事として書かれています。 qiita.com はじめに 私が数式を含むブログ記事を投稿するときの手順を紹介したいと思います。あくまで私が気に入っている方法であり、他にもよい方法があると思います。参考になれば幸いです。 例えば、以下のような数式が多い記事をブログ投稿したい場合を考えます。 kentapt.hatenablog.com そのような場合は、ここで紹介する方法が効果的でした。 大まかな手順として、以下の流れを想定しています。 1 内容をまとめ、ブログに掲載する数式を用意する 2 記事を執筆する 3 ブログ投稿がしやすい形で記事や画像をエキスポートする（マークダウン形式） 4 記事を投稿する ここでは以下のものが必要です。 ペンシルで、すらすらメモがかけるタブレット端末（≒iPadとappleペンシル） MATLAB 手順 手順1 内容をまとめ、ブログに掲載する数式を用意する はじめに、ブログに書くような数式やその流れを考える必要があります。ここではその作業が完了していることを想定します。私は、以下のアプリを利用しています。もし、iPadをお持ちの方はぜひダウンロードしてみてください。 Nebo: メモ &amp; PDF 注釈 MyScript 仕事効率化 無料 apps.apple.com 使い方は簡単です。以下の赤枠で示されているように、数式を入れるモードがあるので、そこで、以下のようにどんどん数式を書いていきます。 ある程度数式がかけたら、右上の、「三つの点・・・」のボタンを選択して、数式に変換してください。 すると、以下の動画のように、高精度で数式を認識して、自動変換してくれます。これよりも複雑なものでも問題ありませんでした。 このような数式の書き込みを重ねて、記事に必要な数式が書けた場合を考えます。 次のステップとしては、このiPad上の数式をブログ投稿できる形でエキスポートします。 以下のボタンをタッチしてください。 出力形式はWordを選択します。 このように、簡単なタッチ操作で、iPadで書いた数式をWordにエキスポートすることができます。（もしかしたらこのあたりで少し課金が必要かもしれません） この作業の後、Google Driveなどを経由して、Wordフ...
</div><div class="ui-feed-item__date" title="2022-12-17 07:01:53">8ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/entry/matlabAdventDay11"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/entry/matlabAdventDay11">サポートベクトルマシンを理解するうえで重要なカーネル法に関して勉強してみよう</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
この記事は、MATLABアドベントカレンダー（その2）の11日目の記事として書かれています。 qiita.com 本記事の執筆にあたっては、 赤穂先生の「カーネル多変量解析」を非常に参考にさせていただきました。 カーネル多変量解析―非線形データ解析の新しい展開 (シリーズ確率と情報の科学) | 赤穂 昭太郎 |本 | 通販 | Amazon 非常にわかりやすい書籍であり、大変おすすめです。 なお、本記事では、機械学習の中でも非常に有名な、サポートベクトルマシン（SVM）を理解するうえで非常に重要な手法（カーネル法）を扱います。機械学習を学習している方の参考になれば幸いです。本記事は自分の勉強のまとめであり、厳密でない記述や間違いなどあるかもしれません。その場合は教えていただけますと幸いです。 この記事の原稿や、コードは以下のページに格納されています。勉強の助けになれば幸いです。 github.com 1. はじめに これまでの記事で、線形回帰について、詳しく述べてきました。そこで用いた図の例としては以下のようなものがあります。しかし、この例では、決定係数も約0.3とあまりうまくフィッティングすることができていません。また、次数を上げて、3次式などでフィッティングしても、ある程度の残差出てしまうことが予想されます。 上の図のような、y = ax+bで表されるような、線形的な回帰ではなく、非線形なフィッティングを考えたいと思います。 ここで、本記事にて、勉強した内容をもとに、カーネル法によるフィッティングを筆者が1から実装してみました。その結果の様子をご覧ください。 サンプルの点（青）に対して、うまくフィッティングできている（赤）ことがわかります。 さきほどの線形回帰よりも、ぐにゃぐにゃとした線でフィッティングされていることがわかります。 このような複雑な形状でフィッティングするにはどのような方法を取ればよいのでしょうか。 2章や3章にて、このフィッティングをするための式について考えていきます。 2. 線形回帰（複数の変数）を行列で表現する 2章では、以前のブログ記事で行った、線形回帰の式の導出を、行列を用いて行います。また、この場合は、変数の数が多くなっても、うまく対応することができます。 線形回帰のときは y=ax+bという式を用意し、以下のように、各yの値...
</div><div class="ui-feed-item__date" title="2022-12-11 11:00:00">8ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/2022/12/06/171941"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/2022/12/06/171941">t-SNEの勉強メモ</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
この記事は、MATLAB/Simulink Advent Calendar 2022の6日目の記事として書かれています。 qiita.com 1章 はじめに t-SNEと呼ばれる方法を用いて、高次元データを、2次元平面や3次元空間にプロットすることができます。 例えば、以下の図は、MNISTという0から9の手書き数字の画像の情報を2次元平面にプロットしたときの様子です。 0から9の画像のサンプルデータが、それぞれクラスタを形成しており、うまく可視化できていることがわかります。 PCA (主成分分析)と呼ばれる方法を用いて、次元圧縮を行い、上のような2次元や3次元上でのプロットを得ることもできます。しかし、主成分分析では、高次元空間上で線形的な構造を有しているものに対して、有効であり、非線形な構造を有しているデータに対しては、うまく低次元空間にマッピングできないという欠点があります。主成分分析については、以下の私の過去の記事をご覧ください。 kentapt.hatenablog.com 本記事の執筆においては、以下のページを参考にさせていただきました。ありがとうございました。 t-SNE 解説 qiita.com Parametric t-SNEの理論とKerasによる実装 qiita.com t-SNE を用いた次元圧縮方法のご紹介 blog.albert2005.co.jp この記事では、初めにt-SNEについて簡単にまとめ、その後、パラメータをいくつか変えながらt-SNEについて勉強していこうと思います。 なお、この記事の原稿やコードは以下のページにて公開されています。 github.com 2章 t-SNEについての自分用まとめ ここからは、t-SNEの処理の流れについておおまかにまとめていきます。より正しい/詳しい解説にて勉強したい方は上の参考ページをご覧ください。 2.1. t-SNEの目標 n次元上に複数の点が存在するといます。その空間上の任意の点のペアを作り、それらを2次元平面（や3次元空間）に写像したときのことを考えます。 (i) 近い点：2次元平面（や3次元空間）に点を写像したときも、それらの点が近いままにする (ii) 遠い点：2次元平面（や3次元空間）に点を写像したときも、それらの点が遠いままにする (i) (ii)のように、高次元と低次元空...
</div><div class="ui-feed-item__date" title="2022-12-05 15:00:00">8ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/matlabAdventDay4"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/matlabAdventDay4">線形回帰（単回帰分析）を1から実装して理解を深めてみよう</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
この記事は、MATLABアドベントカレンダー（その2）の4日目の記事として書かれています。 qiita.com 1 はじめに 以下の図のように、エクセルなどで、直線で回帰（フィッティング）した経験がある方も多いかもしれません。 以下の図では、y = 0.33x + 50.2 という式が得られています。 例えば、これにより、データ同士の相関関係を知ることができ、非常によく用いられる解析方法です。 このような線形回帰（単回帰）の説明としては、以下のページがわかりやすかったです。 回帰分析(単回帰分析)をわかりやすく徹底解説！ udemy.benesse.co.jp 実は簡単！ 10分あれば回帰分析ができます cacco.co.jp よく用いられる手法ではありますが、それを実際に、導出し、自分の手で（プログラミングやExcelを使って）検算したことのある人は、 あまり多くないかもしれません。ここでは、自分の勉強のまとめとして、線形回帰の中でも、1つの変数を用いた、単回帰の導出を行い、さらに、複数の方法での実装（プログラミング）により自身の理解が正しいことを確認します。なお、実装による確認などを通して、検算はしていますが、間違いなどあるかもしれません。その場合は教えていただけますと幸いです。 この記事の原稿や、コード、検算用のExcelファイルは以下のページに格納されています。勉強の助けになれば幸いです。 github.com また、線形回帰に関しては、本記事の内容は、最初の一歩のみを紹介しています。線形回帰を実際の研究や実務に利用したい方は、 以下の動画が大変参考になると思います。 www.youtube.com 2 解析方法 単回帰分析では、データによくあてはまる直線を考えます。以下に、そのイメージを示します。 直線は、数式で、y = ax+bという形で表すことができます。この直線を下の図では、緑で表しています。 単回帰分析では、この直線と、各サンプルとのちがい（残差）が最小になるような直線を求めます。 そのために、最小二乗法を用いていきます。 図出展：残差とは何か？正規分布していることの意味をわかりやすく解説！ best-biostatistics.com 最小二乗法については、以下の記事がわかりやすかったです。 最小二乗法（直線）の簡単な説明 | 高校数学の美し...
</div><div class="ui-feed-item__date" title="2022-12-03 15:18:35">8ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/matlabQiita"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/matlabQiita">iPhone LiDARで取得した3次元点群を地図上にプロットしてみよう</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
この記事は、MATLABアドベントカレンダー3日目の記事として書かれています。 qiita.com この記事では、iPhone LiDARで取得した3次元点群をMATLABにて読み込み、さらに、地図（地球）上で可視化する方法について紹介します。言語はMATLABを使用します。 3次元点群を取得するためのアプリはScaniverseを用いました。 scaniverse.com 詳しい使い方は、以下の記事がわかりやすかったです。ここでは、すでにiPad LiDARにて計測し、PCに転送した状態から始めます。 note.com PCに転送（エキスポート）する方法は以下の図の通りです。右下のShareボタンから行うことができます。 なお、3次元モデルをエキスポートする際は、一番下のLAS形式を選択してください。 なお、ここで用いたコードや、点群ファイルは以下のページにアップロードされています。ぜひ、ダウンロードしてお使いください。 github.com 点群ファイルの読み込み LiDAR toolboxの機能を用いて、点群データの読み込みを行います。以下のように、lasFileReaderやreadPointCloud関数を用いて、簡単に点群ファイルを読み込むことができます。 clear;clc;close all % las/lazファイルを読み込むためのlasFileReader objectを作成する lasReader = lasFileReader(&#39;treeTrunk.laz&#39;); % las/lazファイルの、xyzおよび色情報を読み込み ptCloud = readPointCloud(lasReader); % 可視化 figure(&#39;Visible&#39;,&#39;on&#39;);pcshow(ptCloud) 以下のように、複雑な3次元形状を有する、樹木の幹部分をきれいに点群化できていることがわかります。iPhone LiDARとアプリ（Scaniverse）を用いることで、お手軽にこのようにきれいな点群を取得できるのは素晴らしいです。 座標系の変換 projcrsオブジェクトの作成 2022年12月においては、Scaniverseで、点群を取得し、エキスポートする場合（LAS形式）、経度・緯度ではなく、2次元平面に投影した方式でxy座標が保存されます。 具...
</div><div class="ui-feed-item__date" title="2022-12-02 15:00:00">8ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/2022/08/20/200038"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/2022/08/20/200038">voxelPlotterを利用して、点群とグリッドを重ね合わせてみよう</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
この記事では、以下のように、3次元点群にグリッドを重ね合わせて表示する方法について紹介します。メインのコードである、VoxelPlotter.mは、以下のMATLAB Centralにて公開されているものを参考にしました。 jp.mathworks.com メインコード アイデアとしては、voxelPlotter.mの結果と、点群をスケールが合うように同時にプロットするということです。なお、voxelPlotter.mについても、グリッドの透明度を変えられるように微調整しています。この記事で用いられたコードは以下のページにアップロードされています。 github.com clear;clc;close all % グリッドサイズの設定。小さくするとよりたくさんグリッドが表示される gridSize = 0.3; % テストデータの読み込み pt = pcread(&#39;teapot.ply&#39;); % 最小値を用いて、原点方向にシフト xyz = pt.Location-[pt.XLimits(1),pt.YLimits(1),pt.ZLimits(1)]; % 点群の変数を作成 pt_shifted = pointCloud(xyz); % シフトしたあとの、座標の最大値を取得 xyzMax = [pt_shifted.XLimits(2),pt_shifted.YLimits(2),pt_shifted.ZLimits(2)]; % グリッドの作成 VoxelMat = ones(round(xyzMax./gridSize)); % 表示 figure(&#39;Visible&#39;,&#39;on&#39;) % メインコード。3つめの引数で、グリッドの透明度を制御できる [vol_handle]=VoxelPlotter(VoxelMat,1,0.3);hold on; pcshow(pt_shifted.Location./gridSize)</div><div class="ui-feed-item__date" title="2022-08-20 11:00:38">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" 
href="https://kentapt.hatenablog.com/entry/2022/06/12/155810"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/2022/06/12/155810">サブフォルダも含めてファイル一覧を取得する</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
1. はじめに この記事では、特定のフォルダの中に存在するファイルを、サブフォルダも含めて取得する方法についてメモを残します。 github.com 2. コードについて 2.1. MATLAB dir関数を用いる際に、\**\と指定すればよい。 % サブフォルダも含め、txtデータを集める txtList = dir(fullfile(pwd, &#39;folder1\**\*.txt&#39;)); %get list of files and folders in any subfolder % 拡張子を含めず、あらゆるファイルを取得する filelist = dir(fullfile(pwd, &#39;folder1\**\*&#39;)); filelist = filelist(~[filelist.isdir]); % フォルダの情報を削除する 2.2. Python globモジュールを用いる場合を考える。MATLABの場合と同様に、Pythonの場合は /*/をつけるとよい。 import os from glob import glob txtFiles = glob(os.getcwd() + &quot;/folder1/*/*.txt&quot;, recursive = True) print(&#39;==== file list ====&#39;) print(txtFiles) for i in txtFiles: print(&#39;==== file name ====&#39;) print(i) # 任意の処理を行う 参考ページ MATLAB公式ドキュメント：dir How to recursively go through all directories and sub directories and process files? MATLABで、あるフォルダ以下のサブフォルダのリストを作る =&gt; 任意の拡張子のファイルパスを取得 (ここでは*.jpg) Python でサブディレクトリを一覧表示する</div><div class="ui-feed-item__date" title="2022-06-12 06:58:10">1年前</div></div></div><div 
class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/2022/05/23/111128"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/2022/05/23/111128">サポートベクターマシン（SVM）の分離平面の可視化 (Python, MATLAB)</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
この記事では、サポートベクトルマシン（SVM）を用いて、分類を行ったときの、分離のための超平面を可視化することを行います。PythonとMATLABにて書いてみたいと思います。ここでは、3つの変数を説明変数として用いて、3次元プロットによる可視化を行います。 可視化におけるポイントは、 SVMによる分類を行う コードは以下のページにアップロードしています。 github.com モジュールのインポート この例では、jupyter notebookを用いています。点を3D上でプロットして、くるくると回すために、%matplotlib notebookと指定します。 from sklearn.svm import SVC import numpy as np import matplotlib.pyplot as plt from sklearn import svm, datasets from mpl_toolkits.mplot3d import Axes3D from scipy.interpolate import griddata %matplotlib notebook irisデータセットの読み込み ここでは、irisデータセットを用います iris = datasets.load_iris() X = iris.data[:, :3] # 3つの変数のみを用いる Y = iris.target # 用いるデータの作成 X = X[np.logical_or(Y==0,Y==1)] Y = Y[np.logical_or(Y==0,Y==1)] SVMの学習 ここでは、ガウシアンカーネルを用いて学習を行います。線形カーネルで行う場合は、&quot;linear&quot;と指定します。 # 分類器の準備 model = svm.SVC(kernel=&#39;rbf&#39;,probability=True) # 学習 clf = model.fit(X, Y) 分離平面を可視化するためのテストデータを作成する 各変数の最大値と最小値を求め、その範囲でテストデータを作成します。mesh_sizeという変数で、その間隔を制御します。小さい値に設定すると、より厳密な分離平面を得ることができますが、一方で、計算時間が長くなります。 # データを作成する間隔 mesh_size...
</div><div class="ui-feed-item__date" title="2022-05-23 02:11:28">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/2022/05/08/211433"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/2022/05/08/211433">文字列・数値に対してゼロ埋めをし、000123.jpgのような文字列を作成する（ゼロパディング）</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
数字の表記を、1234ではなく、001234のように特定の数字などで埋めたい場合があると思います。この記事では、MATLABとpythonにおけるコードについて自分用のメモとして残したいと思います。例えば、 123, 18, 1931...のように桁数の違う数字を含むファイル名において、00123.jpg, 00018.jpg, 01931.jpgのようにすると統一性が出る file1.txt, file2.txt, file10.txtを並び替えると、file1.txt, file10.txt, file2.txtという順番になる場合がある。ファイル名からゼロで埋めると数字の大きさ（小ささ）の順に並び変えられる。 といった場合に有効であると考えられます。 MATLABの場合 sprintf(&#39;%07d&#39;, 1234) とすれば、0001234という値（char）が返されます。 jp.mathworks.com 並び替えをうまく行いたい場合は、sort_natを使うこともできます。 jp.mathworks.com pythonの場合 v = &#39;1234&#39; v.zfill(7) のように、zfillを用いるとよいです。vは文字列であることに注意する必要があります。他にも複数方法が存在するようです。以下のページが参考になりました。 note.nkmk.me 今回のメモの原稿や他の記事のコードやデータはこちらにアップロードしています。 github.com</div><div class="ui-feed-item__date" title="2022-05-08 12:14:33">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/2022/04/10/162216"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div 
class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/2022/04/10/162216">Linux (Ubuntu)でMATLABを使用する際、Windowsのショートカットキーを割り当てる方法について</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">1. はじめに LinuxでMATLABを使用する際、デフォルトではWindowsと異なるショートカットキーが割り当てられていたため、不便でした。コピーやペーストなどのショートカットキーをWindows版のMATLABと同じように設定したいと思いました。 2. 方法 ホームタブの「基本設定」をクリック キーボード=&gt;ショートカットをクリック アクティブ設定をWindows既定の設定に変更する このような操作で簡単に変更することができました。普段Windowsを使っている場合は、同様にショートカットキーを使えるので便利だと思います。 参考ページ jp.mathworks.com</div><div class="ui-feed-item__date" title="2022-04-10 07:22:16">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/2022/03/20/232253"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" 
href="https://kentapt.hatenablog.com/entry/2022/03/20/232253">MATLABのNormalize関数で使った平均と標準偏差を保持して、未知データに対しても同じ演算をする＋もとのスケールに戻す</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
データ分析において、対象のデータをスケーリングしたい場合、例えば、平均0・分散1になるよう変換する場合が多いと思います（標準化）。MATLABでは、normalize関数を用いれば1行で済むため、非常に便利です。しかし、同様の式を用いて、別のデータも標準化したいときがあります。または、標準化したものをもう一度もとのスケールに直したい、といったこともあります。その場合は、normalize関数の戻り値に、その標準化に用いた平均値・標準偏差を指定することで、そのような追加の変換や、もとのスケールへの再変換が簡単に行えます。 公式ドキュメントは以下の通りです。 jp.mathworks.com はじめに、normalize関数は、 N = (A - C) ./ S を満たす C と S を配列として返します。 とあります。Cが平均、Sが標準偏差であると思われます。methodtypeで指定できる、標準化の方法が複数ありますが、今回は、既定であるz-scoreとします。 整数を30個生成してみます。 data=randi(100,[30,1]);%100までの整数を30個生成する これをnormalize関数を用いて標準化します。ここでは、後ろ2つの戻り値を指定することがポイントです。先頭の1つしか指定しない場合が多い気がしますが、このように3つ指定すると便利です。。 [N,average,stdev]=normalize(data); % 戻り値にaverage, standard deviationを指定できる 標準化したあとの値を見てみます N N = 30x1 -1.0634 1.7534 -1.3910 1.1311 1.2621 1.4259 -1.1289 -0.1135 -0.5721 1.2294 検算のため、平均を引いて、標準偏差で割れば同じ値になることを確認します。 N_check=(data-average)/stdev N_check = 30x1 -1.0634 1.7534 -1.3910 1.1311 1.2621 1.4259 -1.1289 -0.1135 -0.5721 1.2294 逆に、標準化したあとに、もとのスケールに戻すことを行います。 data_check=N*std...</div><div 
class="ui-feed-item__date" title="2022-03-20 14:22:53">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/2022/02/23/122306"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/2022/02/23/122306">画像の2値化の方法を数式から理解したい</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
1 はじめに 2 2値化の方法について 2-1 2値化の方法のイメージ 2-2 クラス内の分散について 2-3 クラス間の分散について 2-4 全分散について 2-4-1 全分散＝クラス内分散＋クラス間分散？ 2-5 閾値の決定について 3 まとめ 参考文献 1 はじめに この記事では、画像を対象として、2値化処理（2値化とする）の方法を説明します。メインパートでは、丁寧に式展開をしながら2値化の方法（判別分析法）の説明を行いました。もし何か間違いがございましたら教えていただけますと幸いです。 この記事の本文のファイル（md形式およびPDF形式）や、この記事のデモのコード（MATLAB, Python）は以下のページにアップロードしています。自学自習や勉強会など何かの役に立てばうれしいです。 github.com なお、この記事は、デジタル画像処理の2値化のページを参考にしていて、そのページを詳しく書いたような構成になっています。2値化をベースにしたさらなる応用例などはデジタル画像処理に記載があります。 早速ですが、以下の画像を見てください。 左の画像は入力画像で、右側が明るいピクセルを白、暗いピクセルを黒で示しています。2値化により、自動的に明るい/暗いピクセルに分けています。この2値化の処理を行うことで、画像に映る対象を自動的に取得したり、画像を大きく分割するといったことができます。 I = imread(&#39;demo_img\img2.jpg&#39;); I_gray = rgb2gray(I); %グレースケールに変換 BW = imbinarize(I_gray,&#39;global&#39;); % global:大津の2値化 figure;imshowpair(I,BW,&#39;montage&#39;);title(&#39;左：入力画像、右：2値化後の画像（明るい部分が抽出できている）&#39;,&quot;FontSize&quot;,14) 図１：2値化を行ったときの例。左が入力画像で、右が2値化を行った後の結果を示す。2値化を行ったことで、明るいピクセルと暗いピクセルを分けることができていることがわかる。 ほかの利用例として、以下の図２を見てください。こちらは、ミブログさまの記事より引用しています。ここでは、顕微鏡画像のようなものから対象のピクセルを取り出しています。例えば、観察したい細胞のエリアの...
</div><div class="ui-feed-item__date" title="2022-02-23 03:23:06">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/2022/02/16/182532"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/2022/02/16/182532">主成分分析 (Principal Component Analysis: PCA)を簡単に、かつわかりやすく説明したい</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
0章：はじめに この記事では、主成分分析や統計に関して初心者の方でも直感的に、かつある程度数式も合わせて理解できるようになることを目指しています。 筆者の勝手な理解をベースに執筆しているため、一部、曖昧な/厳密でない 表現があるかもしれません。 筆者の理解に従い、自身で主成分分析を1からコーディングし、数値計算のソフトウェアによって主成分分析をした結果とおおむね結果が一致していることを確かめています。これにより筆者の理解が正しいか確認いたしました。 もし間違いなどあれば教えていただけると幸いです。 本記事の原稿のマークダウンファイルや、PDFファイルは以下のページにアップロードしています。文字化けがある場合や、何かのまとめに使いたい場合は以下からダウンロードしていただけますと幸いです。 github.com また、pythonによる主成分分析のお試しのコード（栄養データを対象）も用意していて、それらは以下のページからダウンロードできます。 github.com 1章： 2次元や3次元で可視化して対象を捉えてみる 1-1 お土産にフルーツを買おう 例えば、お土産として、フルーツを友人宅に持っていくときのことを想像してください。どのフルーツを持っていくかを決定する方法としては、パッと浮かんだおいしいフルーツを買っていく、近くのスーパーに売っている旬のものを買う、友人と食べる夕食のメニューに合いそうなものを思い浮かべる、などがあると思います。メニューに合うように、味を考慮して選ぶとすれば、例えば、以下のように、グループ分けをすることも可能でしょう。思い浮かんだフルーツを、甘い/酸っぱいの基準にグループ分けし、甘いものがいいか、酸っぱいものがいいか、甘くて酸っぱいものがいいか、など考えることができます。甘くて、酸っぱくないものがいい、となれば柿などが候補になるでしょう。 実際に、上のようにグループ分けをしてフルーツを選ぶかどうかは人によるでしょう。しかし、複数の候補から最適なものを選んだり、複数の対象を関連付けて考えることにおいて、上のような関係性を可視化することは重要です。 例えば、上のグループ分けの図から ゆずとみかんは似た味の系統である 甘いものとしては、柿がある 甘さという観点において、柿とレモンは対極にある アボカド（実はフルーツと区分される）は...</div>
<div class="ui-feed-item__date" title="2022-02-16 09:25:32">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/2022/01/31/090906"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/2022/01/31/090906">PR曲線による平均適合率の計算について勉強＆自分で書いて確認してみた</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
この記事では、物体検出を行ったときの精度の指標である、平均適合率について扱います。 この記事を執筆するにあたって、原田達也先生の「画像認識」の7.7.2 平均適合率を参考にいたしました。詳しくはこの本をご参照ください。 はじめに ここでいう物体検出とは、以下の図のように、画像中から関心のある物体を検出することです。検出された物体は黄色の箱（以下、バウンディングボックスという）で囲まれていることがわかります。また、下の図では、あえて少し車の領域からずらしてバウンディングボックスを作成しています。 これを検出結果だとすると、この検出の結果を評価するためには、どうのようにすればよいでしょうか。代表的な物体検出の評価として、平均適合率によるものが挙げられます。この記事では、この平均適合率について勉強したことをまとめます。 また、この記事のために実装したコードは以下のgithubページにアップロードしています。 github.com この記事は以下のような構成になっています。 1) 前半部分：平均適合率についての説明 後半部分：前半部分の理解が正しいかを確かめるために実際に自分で実装してみる 2の部分でも、公式の関数と比べて、おおよそ正しい値が出ているので、大きな間違いはないとは思うのですが、私の理解違いやわかりにくい部分もあるかもしれません。その場合は教えていただけますと幸いです。 画像出典：What Is Object Detection? 3 things you need to know (以下も同様） 物体検出の評価をするときの準備 物体検出の性能を評価するためには、まず、正解となるバウンディングボックスの情報が必要です。下の図では赤色のバウンディングボックスで示されています。 はじめに示した、検出の結果（黄色のバウンディングボックス）と比べると、より車の領域を正しく捉えられていることがわかります。 このように、平均適合率では、正解データとしてのバウンディングボックスと、検出の結果としてのバウンディングボックスを比べ、計算していきます。 IoUについて 上の図では、２つの自動車を検出していて、どちらの検出も正しく行えていそうです。ただ、以下の例のように、検出結果（黄色）が、正解のバウンディングボックス（赤）に比べて、非常に小さかったり、横方向にずれていると...
</div><div class="ui-feed-item__date" title="2022-01-31 00:09:06">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/2021/12/16/105958"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/2021/12/16/105958">説明可能なAI：Score-CAMによる判断根拠の可視化 (Wang et al., CVPR workshop, 2020)</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
この記事は、MATLAB/Simulink Advent Calendar 2021（カレンダー2）の18日目の記事として書かれています。 qiita.com はじめに この記事では、深層学習（ここでは、畳み込み込みニューラルネットワーク）で画像分類を行ったときの、判断根拠の可視化に関して扱います。CAMやgrad-cam, LIMEなどが有名ですが、今回はScore-CAMと呼ばれる手法について勉強したのでここにまとめたいと思います。また、勉強のために、私自身で実装も行いました。 LIMEに関しては、私の別の記事で扱っており、こちらも見ていただけますと幸いです。 kentapt.hatenablog.com 実装のためのコードやデータはこちらにアップロードしてあります。 深層学習の結果に対する「なぜ？」を扱う、説明可能AIについては、例えば以下の記事がわかりやすかったです。 xtech.nikkei.com 本稿で紹介する論文は以下のものです。 Wang, H., Wang, Z., Du, M., Yang, F., Zhang, Z., Ding, S., Mardziel, P. and Hu, X., 2020. Score-CAM: Score-weighted visual explanations for convolutional neural networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops (pp. 24-25) こちらのブログで掲載したコードはここにアップロードしています。 github.com 著者らによる公式の実装はこちらになります。私のコードもリンクしていただいているようです。 github.com イントロダクションの和訳 深層学習を用いた画像分類の判断根拠の可視化の方法はいくつか有名なものがあり、本手法との比較などについて気になりました。そこで、以下に、私の勝手な解釈に基づいた論文のイントロダクションの和訳を掲載します。意訳なども含むのでご注意ください。 イントロの中での序論 ディープニューラルネットワーク(DNN)の判断根拠の説明により、人間がそのモデルを解釈する上で重要...
</div><div class="ui-feed-item__date" title="2021-12-16 01:59:58">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/2021/12/12/172625"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/2021/12/12/172625">ナイーブベイズを用いた迷惑メールの検出をやってみた</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
この記事は、MATLAB/Simulink Advent Calendar 2021（カレンダー2）の13日目の記事として書かれています。 qiita.com この記事では、ナイーブベイズと呼ばれる手法を用いて、ある文面をみて、それが迷惑メールかどうかを判別します。 注意 筆者はこの分野の全くの素人で、あくまで「入門してみた」という記事になります。間違いなどがあれば、教えていただけますと幸いです。 こちらの記事で用いたコードはこちらにアップデートしています。何かの役に立てば嬉しいです。 github.com MATLAB file exchangeにも紐づいていて、ここからもダウンロードすることができます。 jp.mathworks.com この例のほかにLSTM(long short term memory)と呼ばれる手法を用いたものもアップロードしてあります。 入門するにあたって勉強させていただいたWEBページ これらの記事を参考にさせていただきました。 機械学習 〜 迷惑メール分類（ナイーブベイズ分類器） 〜 qiita.com 自然言語処理（NLP）とは | 仕組み・活用例・今後の課題 ledge.ai https://jp.mathworks.com/help/textanalytics/ug/classify-text-data-using-deep-learning.html 入門するにあたって読んだ論文 初学者でも読める論文がないか探してみると以下のものが見つかりました [1]。2021年12月12日時点で、引用数は450で、たくさん引用されてるようですし、私も一部読んでみることにしました。 Vijayarani, S., Ilamathi, M.J. and Nithya, M., 2015. Preprocessing techniques for text mining-an overview. International Journal of Computer Science &amp; Communication Networks, 5(1), pp.7-16. イントロダクションの和訳 以下に、私の勝手な解釈に基づいた論文のイントロダクションの和訳を掲載します。意訳なども含むのでご注意ください。 テキストマイニングとは、テキストデータから有...
</div><div class="ui-feed-item__date" title="2021-12-12 08:26:25">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/2021/12/11/231001"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/2021/12/11/231001">シンプルかつ高精度な姿勢推定の手法について学んでみた（Xiao et al., ECCV, 2018）</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
この記事は、MATLAB/Simulink Advent Calendar 2021（カレンダー2）の12日目の記事として書かれています。 qiita.com 本記事で紹介するネットワークで動画から姿勢推定をした時の結果の例 また、7日目や8日目（カレンダー1）でも記事を投稿していて、もしよろしければこちらもご覧いただけると幸いです。 kentapt.hatenablog.com kentapt.hatenablog.com この記事での取り組みは以下のような姿勢推定と呼ばれるものです。自動的に人間の腕や頭、足の情報を取得できていることがわかります。この手法について、私のほうで論文やコードを見ながら勉強したので、ここで、共有させていただきたいと思います。ここでは、姿勢推定のみを扱います。間違いや誤字などがあれば教えていただけますと幸いです。 この記事で紹介する手法を用いて、動画から姿勢推定を行ったときの結果の例 動画出展：pixabay（フリー動画素材: URL） このように、いい感じに、骨格の情報を画像から推定できていて、見ているだけでも楽しいだけでなく、実際に姿勢推定は産業系（製造・建設など）やスポーツ、研究・教育用途、エンターテインメント、医療・リハビリなど多くの業界で役立つようです。 www.next-system.com なお、ここで紹介する実装は、私自身でなく、こちらのTohruKさんのものです。非常にわかりやすいコードで大変勉強になりました。ありがとうございました。 紹介する手法について この記事では、Xiaoら（2018）の Simple Baselines for Human Pose Estimation and Trackingという論文で提案されている手法について取り上げます。この手法の特徴としては、 シンプルな手法である 高精度である 他の手法と比べる際のベースライン（基準）になりえる よりアップデートされたモデルを考える手助けになる これらのタスクの評価が簡単になる といった感じだと思います。この手法だけでなく、多くの手法が提案されていて、この手法の特徴や立ち位置については、実際にもととなる論文のイントロダクションを読むのが良いと思います。以下に、私の勝手な解釈に基づいた論文のイントロダクションの和訳を掲載します。意訳なども含...
</div><div class="ui-feed-item__date" title="2021-12-11 14:10:01">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/2021/12/06/224424"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/2021/12/06/224424">Explainable AI:LIMEを用いた判断根拠の可視化</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
こちらの記事は、MATLAB/Simulink Advent Calendar 2021の8日目の記事として書かれたものです。 qiita.com また、7日目も記事を投稿していて、もしよろしければこちらもご覧いただけると幸いです。 kentapt.hatenablog.com はじめに この記事では、LIMEとよばれる手法を用いて、畳み込みニューラルネットワーク（CNN）によって画像分類を行ったときの判断根拠の可視化（どのような部分を見て、その分類結果に至ったのか）を行います。画像に対して適用するときの仕組みをここでは説明したいと思います。この画像をもととなる論文はこちらになります： LIME (Local Interpretable Model-agnostic Explanations) 。 また、こちらからも入手することができます。これをMATLAB実装した2020年夏ごろは、公開されている唯一のMATLAB実装だった（と思う）のですが、2020年秋バージョンからimageLimeという関数が、MATLABで公式実装され、１行で実行できるようになりました。ご自身の研究などで使う際は、こちらの公式の実装を使い、そして、その内容を確認したい場合には以下のリポジトリを利用すると良いかもしれません。 （注意）こちらの記事は、チェックはしておりますが、理解違いやミスがあるかもしれません。予めご了承ください。 この記事のコードやデータはこちらのページからダウンロードすることができます github.com LIMEについて 例えば、下の犬の画像を例とすると、CNNによって犬であると分類した際に、どのような箇所に注目してこの分類結果に至ったかということを示しています。赤っぽい色の方が影響が強いことを示しています。LIMEは、画像データだけでなく、表形式のデータなど、ほかのデータ形式に関しても利用可能です。ここでは、画像データを対象として、実装していきます。 LIMEについて：もととなる論文のイントロダクションの和訳 こちらの手法については、もととなっているRibeiroら (2016)の論文のイントロダクションの部分を読むのが良いと思います。以下に、和訳を掲載します。一部、筆者の解釈による意訳を含みます。 機械学習は、近年の科学技術の進歩の中核をなすものであるが、この分...
</div><div class="ui-feed-item__date" title="2021-12-06 13:44:24">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://kentapt.hatenablog.com/entry/2021/12/06/014209"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://kentapt.hatenablog.com/entry/2021/12/06/014209">Spatial CNNを用いた車線検出</a><div class="ui-feed-item__blog-title">matlab - kentaPtの日記</div><div class="ui-feed-item__summary">
この記事は、MATLAB/Simulink Advent Calendar 2021の7日目の記事として書かれています。 qiita.com また、8日目も記事を投稿していて、もしよろしければこちらもご覧いただけると幸いです。 kentapt.hatenablog.com また、ここで用いるコードなどはこちらからダウンロード可能です。 もし、本記事に誤りや誤字が含まれていれば、教えていただけますと幸いです。 github.com はじめに Spatial CNNとよばれる手法を用いて、運転動画から車線検出を行います。ここで得られる結果の例を以下に示します。自分のいるレーンの車線とその横の車線の合計４つの線が検出されています。こちらは車載カメラからの動画を入力とし、深層学習ネットワークを用いて車線の検出を行っています。赤や青で自動的に車線を認識できていることがわかると思います。本記事では、Spatial CNNと呼ばれる方法で、動画から自動的に車線を検出する方法について説明します。 動画出展：Spatial CNNをテストするために、映像素材さまの「車載動画 ４K 夕方の東京スカイツリー【無料フリー動画素材】/japan free video」より、使わせていただきました。ありがとうございました。 コード こちらにある、spatial CNNのMATLAB実装のコードを用いて行います。作成者のricheek-MWさまに感謝いたします。githubからダウンロードとし、ZIPファイルを解凍するか、gitbashでgit cloneコマンドを用いるなどして、ダウンロードしてください。 Spatial CNNについて：もととなる論文 のイントロダクションの和訳 こちらの手法については、もととなっているPanら (2018)の論文のイントロダクションの部分を読むのが良いと思います。以下に、和訳を掲載します。一部、筆者の解釈による意訳を含みます。 近年、自動車の自律走行は学術界や産業界で大きな注目を集めている。その自律走行における最も困難な課題の一つは、その場の交通状況の理解であり、例えば、自動的に周辺環境を理解するために、画像を用いて車線を検出したり、セマンティックセグメンテーションなどが行われてきた。車線の検出は、車線変更など車両を自動的に移動させる際に役立ち、運転支援...
</div><div class="ui-feed-item__date" title="2021-12-05 16:42:09">2年前</div></div></div></div></div></section></main><footer role="contentinfo" class="ui-section-footer"><div class="ui-layout-container"><div class="ui-layout-column-6 ui-layout-column-center"><div class="ui-component-cta ui-layout-flex ui-section-footer__site-info"><p class="ui-text-note">MATLAB/Simulink に関するブログの更新をまとめたRSSフィードを配信しています。MATLAB の使い方・MATLAB を使った新しいアイデアのヒントが得られますように。</p></div></div></div><div class="ui-layout-container"><div class="ui-section-footer__layout ui-layout-flex"><p class="ui-section-footer--copyright ui-text-note"><a class="ui-text-note" href="https://github.com/minoue-xx/"><small>@minoue</small></a></p><a href="https://github.com/minoue-xx/MATLAB-blog-rss-feed/" role="link" aria-label="#" class="ui-text-note"><small>GitHub</small></a></div></div></footer></body></html>